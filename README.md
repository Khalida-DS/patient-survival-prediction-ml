# Patient Survival Prediction â€” Clinical Decision Support System

![Python](https://img.shields.io/badge/Python-3.11+-blue)
![MLflow](https://img.shields.io/badge/MLflow-tracking-orange)
![CI](https://img.shields.io/badge/CI-GitHub_Actions-green)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

> A production-grade machine learning system for one-year patient survival
> prediction. Built with rigorous statistical validation, full model
> explainability (SHAP), experiment tracking (MLflow), data drift monitoring
> (Evidently), and a clinical Streamlit interface.

ğŸš€ **[Live Demo](https://patient-survival-prediction-ml-mzrrwnlfgjsjnvxygywcoa.streamlit.app/)**

---

## Problem Statement

Healthcare providers often lack actionable, data-driven insight into which
factors most strongly influence one-year patient survival. This results in
delayed risk identification, inconsistent treatment comparisons, and limited
support for evidence-based decisions.

This system addresses that gap by combining machine learning with clinical
interpretability â€” producing not just predictions, but *explainable,
calibrated* predictions that clinicians can scrutinise and trust.

---

## Key Data Insights (from EDA)

Before any modeling, EDA revealed several important findings:

| Finding | Action Taken |
|---|---|
| `Treated_with_drugs` had trailing whitespace ("DX1 ") | Stripped on load |
| `Patient_mental_condition` constant ("Stable" for all rows) | Dropped â€” zero information |
| `"Cannot say"` smokers have 100% survival rate | Dropped â€” data artifact |
| 9 patients with age > 120 (max: 149) | Capped at 100 â€” data entry errors |
| `Diagnosed_Condition` correlation with survival = 0.004 | Dropped â€” near-zero signal |
| **DX6 alone = only 42.6% survival** vs 75â€“88% for others | Highlighted in app |

---

## Model Performance

| Metric | Score | Notes |
|---|---|---|
| AUC-ROC | 0.88 | Primary selection criterion |
| Accuracy | 0.83 | |
| F1 Score | 0.82 | |
| Sensitivity | 0.85 | 85% of survivors correctly identified |
| Specificity | 0.81 | |
| Brier Score | 0.14 | Calibration quality â€” lower is better |

### 5-Model Benchmark (CV AUC)

| Model | Mean AUC | Std | Selected |
|---|---|---|---|
| **Gradient Boosting** | **0.87** | 0.02 | âœ… |
| XGBoost | 0.86 | 0.02 | |
| LightGBM | 0.85 | 0.03 | |
| Random Forest | 0.84 | 0.02 | |
| Logistic Regression | 0.78 | 0.03 | |

Selected based on AUC stability across folds â€” not just peak score.

---

## Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LAYER                       â”‚
â”‚  Raw CSV â†’ EDA â†’ Validation â†’ sklearn Pipeline     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TRAINING LAYER                     â”‚
â”‚  5-Model CV Benchmark â†’ RandomizedSearchCV         â”‚
â”‚  Platt Scaling Calibration â†’ MLflow Tracking       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               EXPLAINABILITY LAYER                  â”‚
â”‚  SHAP Global Summary â†’ Per-Patient Waterfall       â”‚
â”‚  Reliability Diagram (Calibration Curve)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 INFERENCE LAYER                     â”‚
â”‚  Input Validation â†’ Streamlit App â†’ Risk Tier      â”‚
â”‚  SHAP Explanation â†’ Evidently Drift Detection      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Project Structure
```
patient-survival-prediction-ml/
â”‚
â”œâ”€â”€ .github/workflows/ci.yml        # Lint â†’ tests â†’ smoke test
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loader.py               # Loading, cleaning, validation
â”‚   â”‚   â””â”€â”€ preprocessor.py        # Leak-free sklearn pipeline
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ benchmark.py            # 5-model CV benchmark
â”‚   â”‚   â”œâ”€â”€ train.py                # Tuning + calibration + MLflow
â”‚   â”‚   â””â”€â”€ predict.py              # Inference with validation
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py              # AUC, F1, Sensitivity, Brier
â”‚   â”‚   â””â”€â”€ calibration.py         # Reliability diagram
â”‚   â”œâ”€â”€ explainability/
â”‚   â”‚   â””â”€â”€ shap_explainer.py       # SHAP global + per-patient
â”‚   â””â”€â”€ monitoring/
â”‚       â””â”€â”€ drift_report.py         # Evidently drift detection
â”‚
â”œâ”€â”€ app/app.py                       # Streamlit clinical interface
â”œâ”€â”€ tests/                           # 15 pytest unit tests
â”œâ”€â”€ config/config.yaml               # Centralised config
â”œâ”€â”€ train_model.py                   # Pipeline entrypoint
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

---

## Quickstart
```bash
# 1. Clone and install
git clone https://github.com/Khalida-DS/patient-survival-prediction-ml.git
cd patient-survival-prediction-ml
pip install -r requirements.txt

# 2. Train the model
python train_model.py

# 3. Launch the app
streamlit run app/app.py

# 4. View MLflow experiments
mlflow ui  # â†’ http://localhost:5000

# 5. Run tests
pytest tests/ -v

# 6. Drift monitoring
python -m src.monitoring.drift_report \
  --reference data/Survival.csv \
  --current data/new_batch.csv \
  --output reports/drift/drift_report.html
```

---

## Tech Stack

Python Â· scikit-learn Â· XGBoost Â· LightGBM Â· SHAP Â·
MLflow Â· Evidently Â· Streamlit Â· Docker Â· GitHub Actions

---

## Disclaimer

For **educational and analytical demonstration purposes only**.
Not a medical device. Must not be used for real clinical
decision-making without regulatory review and prospective validation.